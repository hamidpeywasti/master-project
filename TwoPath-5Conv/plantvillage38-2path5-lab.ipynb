{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":658267,"sourceType":"datasetVersion","datasetId":277323}],"dockerImageVersionId":30635,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"basename = 'PlantVillage38-2Path5-LAB-m4-'\nmonitor='val_accuracy'\nepochs=90\nbatch_size=32\ninput_shape=(128, 128, 3) # please resize it to (224,224,3) if you have enough RAM\nVerbose=True","metadata":{"execution":{"iopub.status.busy":"2024-01-23T18:29:59.585338Z","iopub.execute_input":"2024-01-23T18:29:59.586096Z","iopub.status.idle":"2024-01-23T18:29:59.592242Z","shell.execute_reply.started":"2024-01-23T18:29:59.586054Z","shell.execute_reply":"2024-01-23T18:29:59.591506Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import sys\nprint(\"Python version:\", sys.version)\n\nimport skimage\nprint('skimage:',  skimage.__version__)\n\nimport tensorflow as tf\nprint('Tensorflow:',tf.__version__)\n\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.utils import plot_model\n\nimport multiprocessing\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.utils import class_weight\n\nimport numpy as np\nimport seaborn as sns\nimport pickle\n\n\nimport matplotlib.pyplot as plt\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2024-01-23T18:32:01.222014Z","iopub.execute_input":"2024-01-23T18:32:01.222397Z","iopub.status.idle":"2024-01-23T18:32:15.130027Z","shell.execute_reply.started":"2024-01-23T18:32:01.222367Z","shell.execute_reply":"2024-01-23T18:32:15.128833Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Python version: 3.10.12 | packaged by conda-forge | (main, Jun 23 2023, 22:40:32) [GCC 12.3.0]\nskimage: 0.21.0\nTensorflow: 2.13.0\n","output_type":"stream"}]},{"cell_type":"code","source":"#apt-get install git python3-opencv\nimport os\n\nif not os.path.isdir('k'):\n  !git clone https://github.com/hamidpeywasti/keras-neural-api k\nelse:\n  !cd k && git pull\n\n!cd k && pip install .\n\n!rm -rf k\n\nimport cai\nimport cai.datasets\nimport cai.models\nimport cai.inception_v3\nimport cai.layers\nimport cai.util\nfrom cai.layers import conv2d_bn","metadata":{"execution":{"iopub.status.busy":"2024-01-23T18:41:12.436379Z","iopub.execute_input":"2024-01-23T18:41:12.437165Z","iopub.status.idle":"2024-01-23T18:41:32.683599Z","shell.execute_reply.started":"2024-01-23T18:41:12.437126Z","shell.execute_reply":"2024-01-23T18:41:32.682229Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Cloning into 'k'...\nremote: Enumerating objects: 1809, done.\u001b[K\nremote: Counting objects: 100% (221/221), done.\u001b[K\nremote: Compressing objects: 100% (144/144), done.\u001b[K\nremote: Total 1809 (delta 135), reused 147 (delta 72), pack-reused 1588\u001b[K\nReceiving objects: 100% (1809/1809), 15.69 MiB | 16.36 MiB/s, done.\nResolving deltas: 100% (1248/1248), done.\nProcessing /kaggle/working/k\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: pandas>=0.22.0 in /opt/conda/lib/python3.10/site-packages (from cai==0.1.7) (2.0.3)\nRequirement already satisfied: scikit-image>=0.15.0 in /opt/conda/lib/python3.10/site-packages (from cai==0.1.7) (0.21.0)\nRequirement already satisfied: opencv-python>=4.1.2.30 in /opt/conda/lib/python3.10/site-packages (from cai==0.1.7) (4.9.0.80)\nRequirement already satisfied: scikit-learn>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from cai==0.1.7) (1.2.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from cai==0.1.7) (1.24.3)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.22.0->cai==0.1.7) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.22.0->cai==0.1.7) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.22.0->cai==0.1.7) (2023.3)\nRequirement already satisfied: scipy>=1.8 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.15.0->cai==0.1.7) (1.11.4)\nRequirement already satisfied: networkx>=2.8 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.15.0->cai==0.1.7) (3.1)\nRequirement already satisfied: pillow>=9.0.1 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.15.0->cai==0.1.7) (9.5.0)\nRequirement already satisfied: imageio>=2.27 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.15.0->cai==0.1.7) (2.31.1)\nRequirement already satisfied: tifffile>=2022.8.12 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.15.0->cai==0.1.7) (2023.8.12)\nRequirement already satisfied: PyWavelets>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.15.0->cai==0.1.7) (1.4.1)\nRequirement already satisfied: packaging>=21 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.15.0->cai==0.1.7) (21.3)\nRequirement already satisfied: lazy_loader>=0.2 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.15.0->cai==0.1.7) (0.3)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21.0->cai==0.1.7) (1.3.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21.0->cai==0.1.7) (3.2.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=21->scikit-image>=0.15.0->cai==0.1.7) (3.0.9)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=0.22.0->cai==0.1.7) (1.16.0)\nBuilding wheels for collected packages: cai\n  Building wheel for cai (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for cai: filename=cai-0.1.7-py3-none-any.whl size=61387 sha256=c2405361f95949171fde973737ebe151b2dde01c35af1accaba4337260622d39\n  Stored in directory: /tmp/pip-ephem-wheel-cache-cq1i68x0/wheels/7f/63/1a/ed2b6234f76aae55efe76492246448486e41178bd0b5682ecf\nSuccessfully built cai\nInstalling collected packages: cai\nSuccessfully installed cai-0.1.7\n","output_type":"stream"}]},{"cell_type":"code","source":"def two_path5_inception_v5(\n                include_top=True,\n                weights=None, #'two_paths_plant_leafs'\n                input_shape=(224,224,3),\n                pooling=None,\n                classes=1000,\n                two_paths=False,\n                deep_two_paths=False,\n                deep_two_paths_compression=0.655,\n                deep_two_paths_bottleneck_compression=0.5,\n                l_ratio=0.5,\n                ab_ratio=0.5,\n                max_mix_idx=10,\n                max_mix_deep_two_paths_idx=-1,\n                model_name='two_path_inception_v3',\n                kType=0,\n                **kwargs):\n    \"\"\"\n    Instantiates the Inception v3 architecture with 2 paths options.\n    \"\"\"\n    img_input = keras.layers.Input(shape=input_shape)\n    if (deep_two_paths):  max_mix_deep_two_paths_idx = max_mix_idx\n\n    if keras.backend.image_data_format() == 'channels_first':\n        channel_axis = 1\n    else:\n        channel_axis = 3\n    \n\n    if two_paths:\n        if (l_ratio>0):\n            l_branch = cai.layers.CopyChannels(0,1)(img_input)\n            l_branch = conv2d_bn(l_branch, int(round(32*l_ratio)), 3, 3, strides=(2, 2), padding='valid')\n            l_branch = conv2d_bn(l_branch, int(round(32*l_ratio)), 3, 3, padding='valid')\n            l_branch = conv2d_bn(l_branch, int(round(64*l_ratio)), 3, 3)\n            l_branch = keras.layers.MaxPooling2D((3, 3), strides=(2, 2))(l_branch)\n\n            l_branch = conv2d_bn(l_branch, int(round(80*l_ratio)), 1, 1, padding='valid')\n            l_branch = conv2d_bn(l_branch, int(round(192*l_ratio)), 3, 3, padding='valid') \n\n        if (ab_ratio>0):\n            ab_branch = cai.layers.CopyChannels(1,2)(img_input)\n            ab_branch = conv2d_bn(ab_branch, int(round(32*ab_ratio)), 3, 3, strides=(2, 2), padding='valid')\n            ab_branch = conv2d_bn(ab_branch, int(round(32*ab_ratio)), 3, 3, padding='valid')\n            ab_branch = conv2d_bn(ab_branch, int(round(64*ab_ratio)), 3, 3)\n            ab_branch = keras.layers.MaxPooling2D((3, 3), strides=(2, 2))(ab_branch)\n\n            ab_branch = conv2d_bn(ab_branch, int(round(80*ab_ratio)), 1, 1, padding='valid')\n            ab_branch = conv2d_bn(ab_branch, int(round(192*ab_ratio)), 3, 3, padding='valid')            \n        \n        if (l_ratio>0):\n            if (ab_ratio>0):\n                x = keras.layers.Concatenate(axis=channel_axis, name='concat_first_block')([l_branch, ab_branch])\n            else:\n                x = l_branch\n        else:\n            x = ab_branch\n    else:\n        single_branch = conv2d_bn(img_input, 32, 3, 3, strides=(2, 2), padding='valid')\n        single_branch = conv2d_bn(single_branch, 32, 3, 3, padding='valid')\n        single_branch = conv2d_bn(single_branch, 64, 3, 3)\n        single_branch = keras.layers.MaxPooling2D((3, 3), strides=(2, 2))(single_branch)\n\n        # x = conv2d_bn(x, 80, 1, 1, padding='valid')\n        x = cai.inception_v3.kInceptionPointwise(single_branch, filters=80, name='single_path', kType=kType)\n        x = conv2d_bn(single_branch, 192, 3, 3, padding='valid')\n\n    x = keras.layers.MaxPooling2D((3, 3), strides=(2, 2))(x)    \n\n    if max_mix_idx >= 0:\n        for id_layer in range(max_mix_idx+1):\n            if (max_mix_deep_two_paths_idx >= id_layer):\n                x = cai.inception_v3.create_inception_v3_two_path_mixed_layer(x,  id=id_layer,  name='mixed'+str(id_layer),\n                    channel_axis=channel_axis, bottleneck_compression=deep_two_paths_bottleneck_compression, \n                    compression=deep_two_paths_compression, has_batch_norm=True, kType=kType)\n            else:\n                x = cai.inception_v3.create_inception_v3_mixed_layer(x,  id=id_layer,  name='mixed'+str(id_layer), channel_axis=channel_axis, kType=kType)\n    \n    if include_top:\n        # Classification block\n        x = keras.layers.GlobalAveragePooling2D(name='avg_pool')(x)\n        x = keras.layers.Dense(classes, activation='softmax', name='predictions')(x)\n    else:\n        if pooling == 'avg':\n            x = keras.layers.GlobalAveragePooling2D()(x)\n        elif pooling == 'max':\n            x = keras.layers.GlobalMaxPooling2D()(x)\n\n    inputs = img_input\n    # Create model.\n    model = keras.models.Model(inputs, x, name=model_name)\n    return model\n\n\ndef plot_history(filename):\n    plt.figure(figsize=(10, 6)) \n\n    # Plot training & validation loss values\n    plt.subplot(1, 2, 1)\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.title('Model Loss')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.legend(['Train', 'Validation'], loc='upper right')\n    plt.ylim(ymin=0, ymax=1.5)\n\n    # Plot training & validation accuracy values\n    plt.subplot(1, 2, 2)\n    plt.plot(history.history['accuracy'])\n    plt.plot(history.history['val_accuracy'])\n    plt.title('Model Accuracy')\n    plt.xlabel('Epoch')\n    plt.ylabel('Accuracy')    \n    plt.legend(['Train', 'Validation'], loc='lower right')\n\n    plt.savefig(filename)\n\n    plt.tight_layout()\n    plt.show()\n    \ndef top_k_accuracy(y_true, y_pred, k=5):\n    \"\"\"\n    Calculate top-k accuracy.\n\n    Parameters:\n    - y_true: True labels (ground truth)\n    - y_pred: Predicted labels (probabilities or scores)\n    - k: Top-k value (default is 5)\n\n    Returns:\n    - Top-k accuracy\n    \"\"\"\n    top_k = np.argsort(y_pred, axis=-1)[:, -k:]\n    correct = np.argmax(y_true, axis=-1)\n    matches = np.any(top_k == correct[:, np.newaxis], axis=-1)\n    accuracy = np.mean(matches)\n    return accuracy","metadata":{"execution":{"iopub.status.busy":"2024-01-23T18:41:54.596310Z","iopub.execute_input":"2024-01-23T18:41:54.596724Z","iopub.status.idle":"2024-01-23T18:41:54.620390Z","shell.execute_reply.started":"2024-01-23T18:41:54.596691Z","shell.execute_reply":"2024-01-23T18:41:54.619479Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"# Loading Data","metadata":{}},{"cell_type":"code","source":"import os\ndata_dir = \"/kaggle/input/plantvillage-dataset/color\"\n\nlabel_of_classes = os.listdir(data_dir)\nprint(\"Classes Lables:\", label_of_classes)\n\nnumber_of_classes = len(label_of_classes)\nprint(\"Number of Classes:\", number_of_classes)\n\ntrain_x, val_x, test_x, train_y, val_y, test_y, classweight, classes = cai.datasets.load_images_from_folders(\n    seed=7,\n    root_dir=data_dir,\n    lab=True,\n    verbose=True,\n    bipolar=False,\n    base_model_name='plantvillage38_leaf',\n    training_size=0.6,\n    validation_size=0.2,\n    test_size=0.2,\n    target_size=(input_shape[0],input_shape[1]),\n    has_training=True,\n    has_validation=True,\n    has_testing=True,\n    smart_resize=True\n)\n\nprint(train_x.shape,val_x.shape,test_x.shape)\nprint(train_y.shape,val_y.shape,test_y.shape)","metadata":{"execution":{"iopub.status.busy":"2024-01-23T18:42:00.866655Z","iopub.execute_input":"2024-01-23T18:42:00.867095Z","iopub.status.idle":"2024-01-23T19:02:22.438999Z","shell.execute_reply.started":"2024-01-23T18:42:00.867062Z","shell.execute_reply":"2024-01-23T19:02:22.437821Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Classes Lables: ['Tomato___Late_blight', 'Tomato___healthy', 'Grape___healthy', 'Orange___Haunglongbing_(Citrus_greening)', 'Soybean___healthy', 'Squash___Powdery_mildew', 'Potato___healthy', 'Corn_(maize)___Northern_Leaf_Blight', 'Tomato___Early_blight', 'Tomato___Septoria_leaf_spot', 'Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot', 'Strawberry___Leaf_scorch', 'Peach___healthy', 'Apple___Apple_scab', 'Tomato___Tomato_Yellow_Leaf_Curl_Virus', 'Tomato___Bacterial_spot', 'Apple___Black_rot', 'Blueberry___healthy', 'Cherry_(including_sour)___Powdery_mildew', 'Peach___Bacterial_spot', 'Apple___Cedar_apple_rust', 'Tomato___Target_Spot', 'Pepper,_bell___healthy', 'Grape___Leaf_blight_(Isariopsis_Leaf_Spot)', 'Potato___Late_blight', 'Tomato___Tomato_mosaic_virus', 'Strawberry___healthy', 'Apple___healthy', 'Grape___Black_rot', 'Potato___Early_blight', 'Cherry_(including_sour)___healthy', 'Corn_(maize)___Common_rust_', 'Grape___Esca_(Black_Measles)', 'Raspberry___healthy', 'Tomato___Leaf_Mold', 'Tomato___Spider_mites Two-spotted_spider_mite', 'Pepper,_bell___Bacterial_spot', 'Corn_(maize)___healthy']\nNumber of Classes: 38\nLoading  38  classes.\nsmart resize is enabled.\nloading train images\ntrain shape is: (32571, 128, 128, 3)\nloading validation images\nvalidation shape is: (10858, 128, 128, 3)\nloading test images\ntest shape is: (10876, 128, 128, 3)\nChannel  0  min: 0.0  max: 1.0\nChannel  1  min: 0.2054719  max: 0.89584607\nChannel  2  min: 0.25959027  max: 0.9427842\nLoaded.\n(32571, 128, 128, 3) (10858, 128, 128, 3) (10876, 128, 128, 3)\n(32571, 38) (10858, 38) (10876, 38)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Fitting Model for L_ratio and AB_ratio","metadata":{}},{"cell_type":"code","source":"for l_ratio in [0,0.25,0.5,0.75,1.00]:\n        \n        basefilename = basename + str(l_ratio)\n        print('Running: '+basefilename)\n          \n        model = two_path5_inception_v5(\n            include_top=True,\n            weights=None,\n            input_tensor=None,\n            input_shape=input_shape,\n            two_paths=True,    \n            pooling='max',\n            classes=number_of_classes,\n            l_ratio=l_ratio,\n            ab_ratio=(1.0-l_ratio),\n            max_mix_idx=4\n        )\n        \n        model.compile(\n            loss='categorical_crossentropy',\n            optimizer=keras.optimizers.SGD(learning_rate=0.01, momentum=0.9, nesterov=True),\n            metrics=['accuracy']\n        )\n          \n        best_result_file_name = basefilename+'-best_result.hdf5'\n          \n        save_best = tf.keras.callbacks.ModelCheckpoint(\n            filepath=best_result_file_name, \n            monitor=monitor, \n            verbose=True,\n            save_best_only=True,\n            save_weights_only=False, \n            mode='max',\n            save_freq='epoch'\n        )\n          \n        history = model.fit(\n            train_x,\n            train_y, \n            epochs=90, \n            batch_size=batch_size,\n            validation_data=(val_x,val_y),\n            callbacks=[save_best],\n            class_weight=classweight,\n            workers=multiprocessing.cpu_count()\n        )\n\n        # Save the history object to a pickle file\n        history_filename = basefilename +'-history.pkl'\n        with open(history_filename, 'wb') as file:\n            pickle.dump(history, file)\n        print(\"History saved.\")\n        \n        \n        print('Testing Last Model: '+basefilename)\n          \n        evaluated = model.evaluate(test_x,test_y)\n          \n        for metric, name in zip(evaluated,[\"loss\",\"acc\",\"top 5 acc\"]):\n            print(name,metric)\n            \n        print('Best Model Results: '+basefilename)\n          \n        model = tf.keras.models.load_model(\n            best_result_file_name,\n            custom_objects={'CopyChannels': cai.layers.CopyChannels}\n        )\n          \n        evaluated = model.evaluate(test_x,test_y)\n          \n        # cai.models.save_model(model, basefilename)\n          \n        for metric, name in zip(evaluated,[\"loss\",\"acc\",\"top 5 acc\"]):\n            print(name,metric)\n        \n        print('Finished: '+basefilename)","metadata":{"execution":{"iopub.status.busy":"2024-01-23T16:30:39.564229Z","iopub.execute_input":"2024-01-23T16:30:39.564708Z","iopub.status.idle":"2024-01-23T18:26:03.520639Z","shell.execute_reply.started":"2024-01-23T16:30:39.564671Z","shell.execute_reply":"2024-01-23T18:26:03.515952Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Running: PlantVillage38-2Path5-LAB-m4-0.75\nEpoch 1/90\n1018/1018 [==============================] - ETA: 0s - loss: 1.0278 - accuracy: 0.6961\nEpoch 1: val_accuracy improved from -inf to 0.56078, saving model to PlantVillage38-2Path5-LAB-m4-0.75-best_result.hdf5\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n  saving_api.save_model(\n","output_type":"stream"},{"name":"stdout","text":"1018/1018 [==============================] - 56s 44ms/step - loss: 1.0278 - accuracy: 0.6961 - val_loss: 1.4958 - val_accuracy: 0.5608\nEpoch 2/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.3427 - accuracy: 0.8826\nEpoch 2: val_accuracy did not improve from 0.56078\n1018/1018 [==============================] - 38s 37ms/step - loss: 0.3426 - accuracy: 0.8826 - val_loss: 2.1532 - val_accuracy: 0.4873\nEpoch 3/90\n1018/1018 [==============================] - ETA: 0s - loss: 0.2447 - accuracy: 0.9147\nEpoch 3: val_accuracy improved from 0.56078 to 0.85209, saving model to PlantVillage38-2Path5-LAB-m4-0.75-best_result.hdf5\n1018/1018 [==============================] - 39s 38ms/step - loss: 0.2447 - accuracy: 0.9147 - val_loss: 0.4735 - val_accuracy: 0.8521\nEpoch 4/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.1433 - accuracy: 0.9499\nEpoch 4: val_accuracy did not improve from 0.85209\n1018/1018 [==============================] - 38s 38ms/step - loss: 0.1433 - accuracy: 0.9499 - val_loss: 0.9096 - val_accuracy: 0.7629\nEpoch 5/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.1053 - accuracy: 0.9626\nEpoch 5: val_accuracy improved from 0.85209 to 0.87898, saving model to PlantVillage38-2Path5-LAB-m4-0.75-best_result.hdf5\n1018/1018 [==============================] - 39s 38ms/step - loss: 0.1052 - accuracy: 0.9626 - val_loss: 0.3924 - val_accuracy: 0.8790\nEpoch 6/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.0810 - accuracy: 0.9692\nEpoch 6: val_accuracy improved from 0.87898 to 0.91195, saving model to PlantVillage38-2Path5-LAB-m4-0.75-best_result.hdf5\n1018/1018 [==============================] - 38s 38ms/step - loss: 0.0810 - accuracy: 0.9693 - val_loss: 0.2869 - val_accuracy: 0.9120\nEpoch 7/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.0620 - accuracy: 0.9778\nEpoch 7: val_accuracy improved from 0.91195 to 0.96804, saving model to PlantVillage38-2Path5-LAB-m4-0.75-best_result.hdf5\n1018/1018 [==============================] - 38s 37ms/step - loss: 0.0620 - accuracy: 0.9778 - val_loss: 0.0988 - val_accuracy: 0.9680\nEpoch 8/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.0598 - accuracy: 0.9792\nEpoch 8: val_accuracy did not improve from 0.96804\n1018/1018 [==============================] - 38s 37ms/step - loss: 0.0597 - accuracy: 0.9792 - val_loss: 0.4161 - val_accuracy: 0.8769\nEpoch 9/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.0432 - accuracy: 0.9834\nEpoch 9: val_accuracy did not improve from 0.96804\n1018/1018 [==============================] - 38s 37ms/step - loss: 0.0432 - accuracy: 0.9834 - val_loss: 0.5896 - val_accuracy: 0.8342\nEpoch 10/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.0350 - accuracy: 0.9873\nEpoch 10: val_accuracy did not improve from 0.96804\n1018/1018 [==============================] - 38s 37ms/step - loss: 0.0350 - accuracy: 0.9873 - val_loss: 0.2014 - val_accuracy: 0.9366\nEpoch 11/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.0318 - accuracy: 0.9891\nEpoch 11: val_accuracy did not improve from 0.96804\n1018/1018 [==============================] - 38s 37ms/step - loss: 0.0318 - accuracy: 0.9891 - val_loss: 0.3341 - val_accuracy: 0.9026\nEpoch 12/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.0216 - accuracy: 0.9926\nEpoch 12: val_accuracy did not improve from 0.96804\n1018/1018 [==============================] - 38s 37ms/step - loss: 0.0216 - accuracy: 0.9926 - val_loss: 0.2021 - val_accuracy: 0.9470\nEpoch 13/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.0182 - accuracy: 0.9934\nEpoch 13: val_accuracy improved from 0.96804 to 0.97532, saving model to PlantVillage38-2Path5-LAB-m4-0.75-best_result.hdf5\n1018/1018 [==============================] - 38s 38ms/step - loss: 0.0183 - accuracy: 0.9933 - val_loss: 0.0772 - val_accuracy: 0.9753\nEpoch 14/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.0156 - accuracy: 0.9945\nEpoch 14: val_accuracy improved from 0.97532 to 0.97919, saving model to PlantVillage38-2Path5-LAB-m4-0.75-best_result.hdf5\n1018/1018 [==============================] - 38s 37ms/step - loss: 0.0156 - accuracy: 0.9945 - val_loss: 0.0703 - val_accuracy: 0.9792\nEpoch 15/90\n1018/1018 [==============================] - ETA: 0s - loss: 0.0136 - accuracy: 0.9953\nEpoch 15: val_accuracy did not improve from 0.97919\n1018/1018 [==============================] - 38s 37ms/step - loss: 0.0136 - accuracy: 0.9953 - val_loss: 0.0850 - val_accuracy: 0.9726\nEpoch 16/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.0114 - accuracy: 0.9957\nEpoch 16: val_accuracy did not improve from 0.97919\n1018/1018 [==============================] - 38s 37ms/step - loss: 0.0114 - accuracy: 0.9957 - val_loss: 0.1264 - val_accuracy: 0.9613\nEpoch 17/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.0117 - accuracy: 0.9961\nEpoch 17: val_accuracy did not improve from 0.97919\n1018/1018 [==============================] - 38s 37ms/step - loss: 0.0118 - accuracy: 0.9961 - val_loss: 0.3781 - val_accuracy: 0.9003\nEpoch 18/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.0142 - accuracy: 0.9947\nEpoch 18: val_accuracy did not improve from 0.97919\n1018/1018 [==============================] - 38s 37ms/step - loss: 0.0142 - accuracy: 0.9946 - val_loss: 0.6545 - val_accuracy: 0.8572\nEpoch 19/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.0174 - accuracy: 0.9932\nEpoch 19: val_accuracy improved from 0.97919 to 0.98545, saving model to PlantVillage38-2Path5-LAB-m4-0.75-best_result.hdf5\n1018/1018 [==============================] - 38s 38ms/step - loss: 0.0173 - accuracy: 0.9932 - val_loss: 0.0450 - val_accuracy: 0.9854\nEpoch 20/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.0102 - accuracy: 0.9963\nEpoch 20: val_accuracy did not improve from 0.98545\n1018/1018 [==============================] - 38s 37ms/step - loss: 0.0102 - accuracy: 0.9963 - val_loss: 0.0983 - val_accuracy: 0.9712\nEpoch 21/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.0111 - accuracy: 0.9962\nEpoch 21: val_accuracy did not improve from 0.98545\n1018/1018 [==============================] - 38s 37ms/step - loss: 0.0111 - accuracy: 0.9962 - val_loss: 0.0536 - val_accuracy: 0.9836\nEpoch 22/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.0077 - accuracy: 0.9977\nEpoch 22: val_accuracy improved from 0.98545 to 0.98840, saving model to PlantVillage38-2Path5-LAB-m4-0.75-best_result.hdf5\n1018/1018 [==============================] - 38s 38ms/step - loss: 0.0077 - accuracy: 0.9977 - val_loss: 0.0370 - val_accuracy: 0.9884\nEpoch 23/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.0060 - accuracy: 0.9981\nEpoch 23: val_accuracy did not improve from 0.98840\n1018/1018 [==============================] - 38s 37ms/step - loss: 0.0059 - accuracy: 0.9981 - val_loss: 0.0535 - val_accuracy: 0.9842\nEpoch 24/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.0040 - accuracy: 0.9985\nEpoch 24: val_accuracy improved from 0.98840 to 0.98950, saving model to PlantVillage38-2Path5-LAB-m4-0.75-best_result.hdf5\n1018/1018 [==============================] - 38s 38ms/step - loss: 0.0040 - accuracy: 0.9985 - val_loss: 0.0366 - val_accuracy: 0.9895\nEpoch 25/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.0039 - accuracy: 0.9987\nEpoch 25: val_accuracy did not improve from 0.98950\n1018/1018 [==============================] - 38s 37ms/step - loss: 0.0039 - accuracy: 0.9987 - val_loss: 0.0388 - val_accuracy: 0.9888\nEpoch 26/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.0030 - accuracy: 0.9991\nEpoch 26: val_accuracy improved from 0.98950 to 0.99107, saving model to PlantVillage38-2Path5-LAB-m4-0.75-best_result.hdf5\n1018/1018 [==============================] - 38s 38ms/step - loss: 0.0030 - accuracy: 0.9991 - val_loss: 0.0300 - val_accuracy: 0.9911\nEpoch 27/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.0024 - accuracy: 0.9993\nEpoch 27: val_accuracy did not improve from 0.99107\n1018/1018 [==============================] - 38s 37ms/step - loss: 0.0024 - accuracy: 0.9993 - val_loss: 0.0293 - val_accuracy: 0.9909\nEpoch 28/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.0026 - accuracy: 0.9990\nEpoch 28: val_accuracy did not improve from 0.99107\n1018/1018 [==============================] - 39s 38ms/step - loss: 0.0026 - accuracy: 0.9990 - val_loss: 0.0370 - val_accuracy: 0.9887\nEpoch 29/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.0033 - accuracy: 0.9993\nEpoch 29: val_accuracy did not improve from 0.99107\n1018/1018 [==============================] - 39s 38ms/step - loss: 0.0033 - accuracy: 0.9993 - val_loss: 0.1362 - val_accuracy: 0.9617\nEpoch 30/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.0061 - accuracy: 0.9982\nEpoch 30: val_accuracy improved from 0.99107 to 0.99143, saving model to PlantVillage38-2Path5-LAB-m4-0.75-best_result.hdf5\n1018/1018 [==============================] - 39s 39ms/step - loss: 0.0061 - accuracy: 0.9982 - val_loss: 0.0305 - val_accuracy: 0.9914\nEpoch 31/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.0051 - accuracy: 0.9986\nEpoch 31: val_accuracy did not improve from 0.99143\n1018/1018 [==============================] - 39s 38ms/step - loss: 0.0051 - accuracy: 0.9986 - val_loss: 0.0684 - val_accuracy: 0.9778\nEpoch 32/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.0116 - accuracy: 0.9961\nEpoch 32: val_accuracy did not improve from 0.99143\n1018/1018 [==============================] - 39s 39ms/step - loss: 0.0116 - accuracy: 0.9961 - val_loss: 0.2059 - val_accuracy: 0.9393\nEpoch 33/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.0138 - accuracy: 0.9959\nEpoch 33: val_accuracy did not improve from 0.99143\n1018/1018 [==============================] - 39s 38ms/step - loss: 0.0138 - accuracy: 0.9959 - val_loss: 0.1124 - val_accuracy: 0.9665\nEpoch 34/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.0041 - accuracy: 0.9989\nEpoch 34: val_accuracy improved from 0.99143 to 0.99153, saving model to PlantVillage38-2Path5-LAB-m4-0.75-best_result.hdf5\n1018/1018 [==============================] - 40s 39ms/step - loss: 0.0041 - accuracy: 0.9989 - val_loss: 0.0292 - val_accuracy: 0.9915\nEpoch 35/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.0042 - accuracy: 0.9989\nEpoch 35: val_accuracy did not improve from 0.99153\n1018/1018 [==============================] - 39s 39ms/step - loss: 0.0042 - accuracy: 0.9989 - val_loss: 0.0293 - val_accuracy: 0.9914\nEpoch 36/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.0107 - accuracy: 0.9968\nEpoch 36: val_accuracy did not improve from 0.99153\n1018/1018 [==============================] - 39s 39ms/step - loss: 0.0107 - accuracy: 0.9968 - val_loss: 0.1074 - val_accuracy: 0.9714\nEpoch 37/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.0035 - accuracy: 0.9990\nEpoch 37: val_accuracy did not improve from 0.99153\n1018/1018 [==============================] - 39s 39ms/step - loss: 0.0035 - accuracy: 0.9990 - val_loss: 0.0323 - val_accuracy: 0.9902\nEpoch 38/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.0018 - accuracy: 0.9995\nEpoch 38: val_accuracy improved from 0.99153 to 0.99226, saving model to PlantVillage38-2Path5-LAB-m4-0.75-best_result.hdf5\n1018/1018 [==============================] - 39s 39ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.0270 - val_accuracy: 0.9923\nEpoch 39/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.0026 - accuracy: 0.9990\nEpoch 39: val_accuracy did not improve from 0.99226\n1018/1018 [==============================] - 39s 38ms/step - loss: 0.0026 - accuracy: 0.9990 - val_loss: 0.0294 - val_accuracy: 0.9913\nEpoch 40/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.0081 - accuracy: 0.9972\nEpoch 40: val_accuracy did not improve from 0.99226\n1018/1018 [==============================] - 39s 38ms/step - loss: 0.0081 - accuracy: 0.9972 - val_loss: 0.0379 - val_accuracy: 0.9893\nEpoch 41/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.0043 - accuracy: 0.9983\nEpoch 41: val_accuracy did not improve from 0.99226\n1018/1018 [==============================] - 39s 38ms/step - loss: 0.0043 - accuracy: 0.9983 - val_loss: 0.0309 - val_accuracy: 0.9912\nEpoch 42/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 0.9994\nEpoch 42: val_accuracy did not improve from 0.99226\n1018/1018 [==============================] - 39s 38ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.0291 - val_accuracy: 0.9919\nEpoch 43/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.0030 - accuracy: 0.9993\nEpoch 43: val_accuracy did not improve from 0.99226\n1018/1018 [==============================] - 39s 38ms/step - loss: 0.0030 - accuracy: 0.9993 - val_loss: 0.0302 - val_accuracy: 0.9912\nEpoch 44/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.0041 - accuracy: 0.9989\nEpoch 44: val_accuracy did not improve from 0.99226\n1018/1018 [==============================] - 39s 38ms/step - loss: 0.0041 - accuracy: 0.9989 - val_loss: 0.0295 - val_accuracy: 0.9914\nEpoch 45/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.0019 - accuracy: 0.9994\nEpoch 45: val_accuracy did not improve from 0.99226\n1018/1018 [==============================] - 39s 38ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.0317 - val_accuracy: 0.9917\nEpoch 46/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 0.9996\nEpoch 46: val_accuracy improved from 0.99226 to 0.99365, saving model to PlantVillage38-2Path5-LAB-m4-0.75-best_result.hdf5\n1018/1018 [==============================] - 39s 39ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.0254 - val_accuracy: 0.9936\nEpoch 47/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 0.9999\nEpoch 47: val_accuracy did not improve from 0.99365\n1018/1018 [==============================] - 39s 38ms/step - loss: 0.0011 - accuracy: 0.9999 - val_loss: 0.0301 - val_accuracy: 0.9909\nEpoch 48/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.0438 - accuracy: 0.9882\nEpoch 48: val_accuracy did not improve from 0.99365\n1018/1018 [==============================] - 39s 38ms/step - loss: 0.0439 - accuracy: 0.9882 - val_loss: 4.0759 - val_accuracy: 0.4328\nEpoch 49/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.0313 - accuracy: 0.9875\nEpoch 49: val_accuracy did not improve from 0.99365\n1018/1018 [==============================] - 39s 38ms/step - loss: 0.0313 - accuracy: 0.9875 - val_loss: 0.0566 - val_accuracy: 0.9828\nEpoch 50/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.0086 - accuracy: 0.9972\nEpoch 50: val_accuracy did not improve from 0.99365\n1018/1018 [==============================] - 39s 38ms/step - loss: 0.0086 - accuracy: 0.9972 - val_loss: 0.0403 - val_accuracy: 0.9881\nEpoch 51/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.0088 - accuracy: 0.9975\nEpoch 51: val_accuracy did not improve from 0.99365\n1018/1018 [==============================] - 39s 38ms/step - loss: 0.0088 - accuracy: 0.9975 - val_loss: 0.0352 - val_accuracy: 0.9896\nEpoch 52/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.0042 - accuracy: 0.9986\nEpoch 52: val_accuracy did not improve from 0.99365\n1018/1018 [==============================] - 39s 39ms/step - loss: 0.0042 - accuracy: 0.9986 - val_loss: 0.0309 - val_accuracy: 0.9908\nEpoch 53/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.0035 - accuracy: 0.9990\nEpoch 53: val_accuracy did not improve from 0.99365\n1018/1018 [==============================] - 39s 39ms/step - loss: 0.0035 - accuracy: 0.9990 - val_loss: 0.0352 - val_accuracy: 0.9900\nEpoch 54/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.0029 - accuracy: 0.9991\nEpoch 54: val_accuracy did not improve from 0.99365\n1018/1018 [==============================] - 39s 39ms/step - loss: 0.0029 - accuracy: 0.9991 - val_loss: 0.0263 - val_accuracy: 0.9923\nEpoch 55/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 0.9998\nEpoch 55: val_accuracy did not improve from 0.99365\n1018/1018 [==============================] - 39s 38ms/step - loss: 0.0015 - accuracy: 0.9998 - val_loss: 0.0266 - val_accuracy: 0.9927\nEpoch 56/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.0010 - accuracy: 0.9998\nEpoch 56: val_accuracy did not improve from 0.99365\n1018/1018 [==============================] - 39s 38ms/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 0.0276 - val_accuracy: 0.9927\nEpoch 57/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.0019 - accuracy: 0.9993\nEpoch 57: val_accuracy did not improve from 0.99365\n1018/1018 [==============================] - 39s 38ms/step - loss: 0.0019 - accuracy: 0.9993 - val_loss: 0.0403 - val_accuracy: 0.9885\nEpoch 58/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.0022 - accuracy: 0.9995\nEpoch 58: val_accuracy did not improve from 0.99365\n1018/1018 [==============================] - 39s 38ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.0474 - val_accuracy: 0.9856\nEpoch 59/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.0012 - accuracy: 0.9998\nEpoch 59: val_accuracy did not improve from 0.99365\n1018/1018 [==============================] - 39s 38ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0267 - val_accuracy: 0.9929\nEpoch 60/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 0.9997\nEpoch 60: val_accuracy improved from 0.99365 to 0.99401, saving model to PlantVillage38-2Path5-LAB-m4-0.75-best_result.hdf5\n1018/1018 [==============================] - 39s 38ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.0245 - val_accuracy: 0.9940\nEpoch 61/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 0.9994\nEpoch 61: val_accuracy did not improve from 0.99401\n1018/1018 [==============================] - 39s 38ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.0290 - val_accuracy: 0.9923\nEpoch 62/90\n1017/1018 [============================>.] - ETA: 0s - loss: 9.5892e-04 - accuracy: 0.9998\nEpoch 62: val_accuracy did not improve from 0.99401\n1018/1018 [==============================] - 39s 38ms/step - loss: 9.5820e-04 - accuracy: 0.9998 - val_loss: 0.0234 - val_accuracy: 0.9937\nEpoch 63/90\n1017/1018 [============================>.] - ETA: 0s - loss: 7.3716e-04 - accuracy: 0.9998\nEpoch 63: val_accuracy did not improve from 0.99401\n1018/1018 [==============================] - 39s 38ms/step - loss: 7.3713e-04 - accuracy: 0.9998 - val_loss: 0.0248 - val_accuracy: 0.9935\nEpoch 64/90\n1017/1018 [============================>.] - ETA: 0s - loss: 8.3371e-04 - accuracy: 0.9998\nEpoch 64: val_accuracy improved from 0.99401 to 0.99411, saving model to PlantVillage38-2Path5-LAB-m4-0.75-best_result.hdf5\n1018/1018 [==============================] - 39s 38ms/step - loss: 8.3314e-04 - accuracy: 0.9998 - val_loss: 0.0238 - val_accuracy: 0.9941\nEpoch 65/90\n1018/1018 [==============================] - ETA: 0s - loss: 5.4176e-04 - accuracy: 0.9998\nEpoch 65: val_accuracy did not improve from 0.99411\n1018/1018 [==============================] - 39s 38ms/step - loss: 5.4176e-04 - accuracy: 0.9998 - val_loss: 0.0252 - val_accuracy: 0.9933\nEpoch 66/90\n1017/1018 [============================>.] - ETA: 0s - loss: 8.5102e-04 - accuracy: 0.9998\nEpoch 66: val_accuracy did not improve from 0.99411\n1018/1018 [==============================] - 39s 38ms/step - loss: 8.5037e-04 - accuracy: 0.9998 - val_loss: 0.0244 - val_accuracy: 0.9937\nEpoch 67/90\n1017/1018 [============================>.] - ETA: 0s - loss: 8.4378e-04 - accuracy: 0.9998\nEpoch 67: val_accuracy improved from 0.99411 to 0.99457, saving model to PlantVillage38-2Path5-LAB-m4-0.75-best_result.hdf5\n1018/1018 [==============================] - 39s 39ms/step - loss: 8.4424e-04 - accuracy: 0.9998 - val_loss: 0.0231 - val_accuracy: 0.9946\nEpoch 68/90\n1017/1018 [============================>.] - ETA: 0s - loss: 5.2300e-04 - accuracy: 0.9999\nEpoch 68: val_accuracy did not improve from 0.99457\n1018/1018 [==============================] - 39s 38ms/step - loss: 5.2305e-04 - accuracy: 0.9999 - val_loss: 0.0242 - val_accuracy: 0.9941\nEpoch 69/90\n1017/1018 [============================>.] - ETA: 0s - loss: 7.2735e-04 - accuracy: 0.9998\nEpoch 69: val_accuracy did not improve from 0.99457\n1018/1018 [==============================] - 39s 38ms/step - loss: 7.2678e-04 - accuracy: 0.9998 - val_loss: 0.0328 - val_accuracy: 0.9914\nEpoch 70/90\n1017/1018 [============================>.] - ETA: 0s - loss: 5.8909e-04 - accuracy: 0.9998\nEpoch 70: val_accuracy did not improve from 0.99457\n1018/1018 [==============================] - 39s 38ms/step - loss: 5.8862e-04 - accuracy: 0.9998 - val_loss: 0.0265 - val_accuracy: 0.9932\nEpoch 71/90\n1017/1018 [============================>.] - ETA: 0s - loss: 4.8824e-04 - accuracy: 0.9998\nEpoch 71: val_accuracy did not improve from 0.99457\n1018/1018 [==============================] - 39s 38ms/step - loss: 4.8792e-04 - accuracy: 0.9998 - val_loss: 0.0256 - val_accuracy: 0.9937\nEpoch 72/90\n1018/1018 [==============================] - ETA: 0s - loss: 6.5848e-04 - accuracy: 0.9999\nEpoch 72: val_accuracy did not improve from 0.99457\n1018/1018 [==============================] - 39s 38ms/step - loss: 6.5848e-04 - accuracy: 0.9999 - val_loss: 0.0256 - val_accuracy: 0.9941\nEpoch 73/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 0.9996\nEpoch 73: val_accuracy did not improve from 0.99457\n1018/1018 [==============================] - 39s 38ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.0252 - val_accuracy: 0.9936\nEpoch 74/90\n1017/1018 [============================>.] - ETA: 0s - loss: 5.2840e-04 - accuracy: 0.9999\nEpoch 74: val_accuracy did not improve from 0.99457\n1018/1018 [==============================] - 39s 39ms/step - loss: 5.2824e-04 - accuracy: 0.9999 - val_loss: 0.0268 - val_accuracy: 0.9932\nEpoch 75/90\n1017/1018 [============================>.] - ETA: 0s - loss: 5.1303e-04 - accuracy: 0.9999\nEpoch 75: val_accuracy did not improve from 0.99457\n1018/1018 [==============================] - 39s 38ms/step - loss: 5.1265e-04 - accuracy: 0.9999 - val_loss: 0.0275 - val_accuracy: 0.9933\nEpoch 76/90\n1017/1018 [============================>.] - ETA: 0s - loss: 4.2385e-04 - accuracy: 0.9999\nEpoch 76: val_accuracy did not improve from 0.99457\n1018/1018 [==============================] - 39s 38ms/step - loss: 4.2857e-04 - accuracy: 0.9999 - val_loss: 0.0288 - val_accuracy: 0.9938\nEpoch 77/90\n1017/1018 [============================>.] - ETA: 0s - loss: 5.6132e-04 - accuracy: 0.9998\nEpoch 77: val_accuracy did not improve from 0.99457\n1018/1018 [==============================] - 39s 38ms/step - loss: 5.6138e-04 - accuracy: 0.9998 - val_loss: 0.0270 - val_accuracy: 0.9938\nEpoch 78/90\n1017/1018 [============================>.] - ETA: 0s - loss: 4.1322e-04 - accuracy: 1.0000\nEpoch 78: val_accuracy did not improve from 0.99457\n1018/1018 [==============================] - 39s 38ms/step - loss: 4.1313e-04 - accuracy: 1.0000 - val_loss: 0.0254 - val_accuracy: 0.9936\nEpoch 79/90\n1017/1018 [============================>.] - ETA: 0s - loss: 4.8989e-04 - accuracy: 0.9998\nEpoch 79: val_accuracy did not improve from 0.99457\n1018/1018 [==============================] - 39s 38ms/step - loss: 4.8987e-04 - accuracy: 0.9998 - val_loss: 0.0248 - val_accuracy: 0.9943\nEpoch 80/90\n1017/1018 [============================>.] - ETA: 0s - loss: 5.3546e-04 - accuracy: 0.9999\nEpoch 80: val_accuracy did not improve from 0.99457\n1018/1018 [==============================] - 39s 38ms/step - loss: 5.3532e-04 - accuracy: 0.9999 - val_loss: 0.0249 - val_accuracy: 0.9945\nEpoch 81/90\n1017/1018 [============================>.] - ETA: 0s - loss: 3.3546e-04 - accuracy: 1.0000\nEpoch 81: val_accuracy did not improve from 0.99457\n1018/1018 [==============================] - 39s 38ms/step - loss: 3.3533e-04 - accuracy: 1.0000 - val_loss: 0.0236 - val_accuracy: 0.9943\nEpoch 82/90\n1017/1018 [============================>.] - ETA: 0s - loss: 3.9272e-04 - accuracy: 0.9999\nEpoch 82: val_accuracy did not improve from 0.99457\n1018/1018 [==============================] - 39s 38ms/step - loss: 3.9245e-04 - accuracy: 0.9999 - val_loss: 0.0241 - val_accuracy: 0.9944\nEpoch 83/90\n1017/1018 [============================>.] - ETA: 0s - loss: 2.5513e-04 - accuracy: 1.0000\nEpoch 83: val_accuracy did not improve from 0.99457\n1018/1018 [==============================] - 39s 38ms/step - loss: 2.5500e-04 - accuracy: 1.0000 - val_loss: 0.0258 - val_accuracy: 0.9942\nEpoch 84/90\n1017/1018 [============================>.] - ETA: 0s - loss: 3.3582e-04 - accuracy: 0.9999\nEpoch 84: val_accuracy did not improve from 0.99457\n1018/1018 [==============================] - 39s 38ms/step - loss: 3.3564e-04 - accuracy: 0.9999 - val_loss: 0.0238 - val_accuracy: 0.9946\nEpoch 85/90\n1017/1018 [============================>.] - ETA: 0s - loss: 2.3436e-04 - accuracy: 1.0000\nEpoch 85: val_accuracy improved from 0.99457 to 0.99484, saving model to PlantVillage38-2Path5-LAB-m4-0.75-best_result.hdf5\n1018/1018 [==============================] - 39s 38ms/step - loss: 2.3418e-04 - accuracy: 1.0000 - val_loss: 0.0233 - val_accuracy: 0.9948\nEpoch 86/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 0.9997\nEpoch 86: val_accuracy did not improve from 0.99484\n1018/1018 [==============================] - 39s 38ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.0330 - val_accuracy: 0.9920\nEpoch 87/90\n1017/1018 [============================>.] - ETA: 0s - loss: 9.6770e-04 - accuracy: 0.9995\nEpoch 87: val_accuracy did not improve from 0.99484\n1018/1018 [==============================] - 39s 38ms/step - loss: 9.6795e-04 - accuracy: 0.9995 - val_loss: 0.0292 - val_accuracy: 0.9922\nEpoch 88/90\n1017/1018 [============================>.] - ETA: 0s - loss: 7.9129e-04 - accuracy: 0.9998\nEpoch 88: val_accuracy did not improve from 0.99484\n1018/1018 [==============================] - 39s 39ms/step - loss: 7.9090e-04 - accuracy: 0.9998 - val_loss: 0.0281 - val_accuracy: 0.9934\nEpoch 89/90\n1017/1018 [============================>.] - ETA: 0s - loss: 7.8899e-04 - accuracy: 0.9998\nEpoch 89: val_accuracy did not improve from 0.99484\n1018/1018 [==============================] - 39s 39ms/step - loss: 7.8844e-04 - accuracy: 0.9998 - val_loss: 0.0271 - val_accuracy: 0.9935\nEpoch 90/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.0013 - accuracy: 0.9997\nEpoch 90: val_accuracy did not improve from 0.99484\n1018/1018 [==============================] - 39s 38ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.0272 - val_accuracy: 0.9933\nHistory saved.\nTesting Last Model: PlantVillage38-2Path5-LAB-m4-0.75\n340/340 [==============================] - 5s 15ms/step - loss: 0.0269 - accuracy: 0.9936\nloss 0.02694275975227356\nacc 0.9935638308525085\nBest Model Results: PlantVillage38-2Path5-LAB-m4-0.75\n340/340 [==============================] - 5s 13ms/step - loss: 0.0252 - accuracy: 0.9941\nloss 0.025235017761588097\nacc 0.9941154718399048\nFinished: PlantVillage38-2Path5-LAB-m4-0.75\nRunning: PlantVillage38-2Path5-LAB-m4-1.0\nEpoch 1/90\n1018/1018 [==============================] - ETA: 0s - loss: 1.6641 - accuracy: 0.5042\nEpoch 1: val_accuracy improved from -inf to 0.61862, saving model to PlantVillage38-2Path5-LAB-m4-1.0-best_result.hdf5\n1018/1018 [==============================] - 50s 42ms/step - loss: 1.6641 - accuracy: 0.5042 - val_loss: 1.2360 - val_accuracy: 0.6186\nEpoch 2/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.7252 - accuracy: 0.7624\nEpoch 2: val_accuracy did not improve from 0.61862\n1018/1018 [==============================] - 37s 36ms/step - loss: 0.7248 - accuracy: 0.7625 - val_loss: 1.9401 - val_accuracy: 0.5365\nEpoch 3/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.4656 - accuracy: 0.8426\nEpoch 3: val_accuracy improved from 0.61862 to 0.72002, saving model to PlantVillage38-2Path5-LAB-m4-1.0-best_result.hdf5\n1018/1018 [==============================] - 37s 36ms/step - loss: 0.4655 - accuracy: 0.8426 - val_loss: 0.9644 - val_accuracy: 0.7200\nEpoch 4/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.3434 - accuracy: 0.8810\nEpoch 4: val_accuracy improved from 0.72002 to 0.80880, saving model to PlantVillage38-2Path5-LAB-m4-1.0-best_result.hdf5\n1018/1018 [==============================] - 37s 37ms/step - loss: 0.3432 - accuracy: 0.8810 - val_loss: 0.5893 - val_accuracy: 0.8088\nEpoch 5/90\n1018/1018 [==============================] - ETA: 0s - loss: 0.2548 - accuracy: 0.9099\nEpoch 5: val_accuracy did not improve from 0.80880\n1018/1018 [==============================] - 37s 36ms/step - loss: 0.2548 - accuracy: 0.9099 - val_loss: 0.8354 - val_accuracy: 0.7607\nEpoch 6/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.2029 - accuracy: 0.9283\nEpoch 6: val_accuracy did not improve from 0.80880\n1018/1018 [==============================] - 37s 36ms/step - loss: 0.2030 - accuracy: 0.9282 - val_loss: 0.7012 - val_accuracy: 0.7907\nEpoch 7/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.1787 - accuracy: 0.9374\nEpoch 7: val_accuracy improved from 0.80880 to 0.88525, saving model to PlantVillage38-2Path5-LAB-m4-1.0-best_result.hdf5\n1018/1018 [==============================] - 37s 36ms/step - loss: 0.1786 - accuracy: 0.9375 - val_loss: 0.3578 - val_accuracy: 0.8852\nEpoch 8/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.1413 - accuracy: 0.9509\nEpoch 8: val_accuracy did not improve from 0.88525\n1018/1018 [==============================] - 37s 36ms/step - loss: 0.1412 - accuracy: 0.9509 - val_loss: 0.5610 - val_accuracy: 0.8289\nEpoch 9/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.0977 - accuracy: 0.9646\nEpoch 9: val_accuracy did not improve from 0.88525\n1018/1018 [==============================] - 37s 36ms/step - loss: 0.0978 - accuracy: 0.9646 - val_loss: 0.6457 - val_accuracy: 0.8214\nEpoch 10/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.0625 - accuracy: 0.9777\nEpoch 10: val_accuracy improved from 0.88525 to 0.90735, saving model to PlantVillage38-2Path5-LAB-m4-1.0-best_result.hdf5\n1018/1018 [==============================] - 37s 36ms/step - loss: 0.0626 - accuracy: 0.9776 - val_loss: 0.3125 - val_accuracy: 0.9073\nEpoch 11/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.0618 - accuracy: 0.9786\nEpoch 11: val_accuracy did not improve from 0.90735\n1018/1018 [==============================] - 37s 36ms/step - loss: 0.0618 - accuracy: 0.9785 - val_loss: 0.3322 - val_accuracy: 0.9043\nEpoch 12/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.0480 - accuracy: 0.9829\nEpoch 12: val_accuracy did not improve from 0.90735\n1018/1018 [==============================] - 37s 36ms/step - loss: 0.0480 - accuracy: 0.9830 - val_loss: 0.3868 - val_accuracy: 0.8910\nEpoch 13/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.0415 - accuracy: 0.9859\nEpoch 13: val_accuracy improved from 0.90735 to 0.91011, saving model to PlantVillage38-2Path5-LAB-m4-1.0-best_result.hdf5\n1018/1018 [==============================] - 37s 36ms/step - loss: 0.0416 - accuracy: 0.9859 - val_loss: 0.3137 - val_accuracy: 0.9101\nEpoch 14/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.0340 - accuracy: 0.9881\nEpoch 14: val_accuracy improved from 0.91011 to 0.94198, saving model to PlantVillage38-2Path5-LAB-m4-1.0-best_result.hdf5\n1018/1018 [==============================] - 37s 36ms/step - loss: 0.0341 - accuracy: 0.9881 - val_loss: 0.1976 - val_accuracy: 0.9420\nEpoch 15/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.0260 - accuracy: 0.9908\nEpoch 15: val_accuracy did not improve from 0.94198\n1018/1018 [==============================] - 37s 36ms/step - loss: 0.0260 - accuracy: 0.9908 - val_loss: 0.2853 - val_accuracy: 0.9197\nEpoch 16/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.0162 - accuracy: 0.9949\nEpoch 16: val_accuracy did not improve from 0.94198\n1018/1018 [==============================] - 37s 36ms/step - loss: 0.0162 - accuracy: 0.9949 - val_loss: 0.2121 - val_accuracy: 0.9400\nEpoch 17/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.0129 - accuracy: 0.9957\nEpoch 17: val_accuracy improved from 0.94198 to 0.95128, saving model to PlantVillage38-2Path5-LAB-m4-1.0-best_result.hdf5\n1018/1018 [==============================] - 37s 36ms/step - loss: 0.0129 - accuracy: 0.9956 - val_loss: 0.1752 - val_accuracy: 0.9513\nEpoch 18/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.0134 - accuracy: 0.9959\nEpoch 18: val_accuracy did not improve from 0.95128\n1018/1018 [==============================] - 37s 36ms/step - loss: 0.0134 - accuracy: 0.9959 - val_loss: 0.2316 - val_accuracy: 0.9375\nEpoch 19/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.0119 - accuracy: 0.9961\nEpoch 19: val_accuracy did not improve from 0.95128\n1018/1018 [==============================] - 37s 36ms/step - loss: 0.0119 - accuracy: 0.9961 - val_loss: 0.2112 - val_accuracy: 0.9406\nEpoch 20/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.0109 - accuracy: 0.9964\nEpoch 20: val_accuracy did not improve from 0.95128\n1018/1018 [==============================] - 37s 36ms/step - loss: 0.0109 - accuracy: 0.9964 - val_loss: 0.1761 - val_accuracy: 0.9502\nEpoch 21/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.0083 - accuracy: 0.9974\nEpoch 21: val_accuracy did not improve from 0.95128\n1018/1018 [==============================] - 37s 36ms/step - loss: 0.0083 - accuracy: 0.9974 - val_loss: 0.5500 - val_accuracy: 0.8591\nEpoch 22/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.0131 - accuracy: 0.9961\nEpoch 22: val_accuracy did not improve from 0.95128\n1018/1018 [==============================] - 37s 36ms/step - loss: 0.0131 - accuracy: 0.9961 - val_loss: 0.2165 - val_accuracy: 0.9411\nEpoch 23/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.0070 - accuracy: 0.9978\nEpoch 23: val_accuracy did not improve from 0.95128\n1018/1018 [==============================] - 37s 37ms/step - loss: 0.0070 - accuracy: 0.9979 - val_loss: 0.2568 - val_accuracy: 0.9324\nEpoch 24/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.0057 - accuracy: 0.9984\nEpoch 24: val_accuracy improved from 0.95128 to 0.95432, saving model to PlantVillage38-2Path5-LAB-m4-1.0-best_result.hdf5\n1018/1018 [==============================] - 38s 37ms/step - loss: 0.0057 - accuracy: 0.9984 - val_loss: 0.1717 - val_accuracy: 0.9543\nEpoch 25/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.0032 - accuracy: 0.9993\nEpoch 25: val_accuracy improved from 0.95432 to 0.95662, saving model to PlantVillage38-2Path5-LAB-m4-1.0-best_result.hdf5\n1018/1018 [==============================] - 38s 37ms/step - loss: 0.0032 - accuracy: 0.9993 - val_loss: 0.1675 - val_accuracy: 0.9566\nEpoch 26/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.0042 - accuracy: 0.9989\nEpoch 26: val_accuracy did not improve from 0.95662\n1018/1018 [==============================] - 37s 37ms/step - loss: 0.0042 - accuracy: 0.9989 - val_loss: 0.1748 - val_accuracy: 0.9552\nEpoch 27/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.0110 - accuracy: 0.9966\nEpoch 27: val_accuracy did not improve from 0.95662\n1018/1018 [==============================] - 37s 37ms/step - loss: 0.0110 - accuracy: 0.9966 - val_loss: 0.1831 - val_accuracy: 0.9519\nEpoch 28/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.0048 - accuracy: 0.9988\nEpoch 28: val_accuracy did not improve from 0.95662\n1018/1018 [==============================] - 37s 37ms/step - loss: 0.0048 - accuracy: 0.9988 - val_loss: 0.1998 - val_accuracy: 0.9478\nEpoch 29/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.0087 - accuracy: 0.9972\nEpoch 29: val_accuracy did not improve from 0.95662\n1018/1018 [==============================] - 37s 37ms/step - loss: 0.0087 - accuracy: 0.9972 - val_loss: 0.2494 - val_accuracy: 0.9363\nEpoch 30/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.0165 - accuracy: 0.9953\nEpoch 30: val_accuracy did not improve from 0.95662\n1018/1018 [==============================] - 37s 37ms/step - loss: 0.0165 - accuracy: 0.9953 - val_loss: 0.2423 - val_accuracy: 0.9362\nEpoch 31/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.0400 - accuracy: 0.9881\nEpoch 31: val_accuracy did not improve from 0.95662\n1018/1018 [==============================] - 37s 37ms/step - loss: 0.0400 - accuracy: 0.9881 - val_loss: 0.7463 - val_accuracy: 0.8301\nEpoch 32/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.0341 - accuracy: 0.9876\nEpoch 32: val_accuracy did not improve from 0.95662\n1018/1018 [==============================] - 37s 37ms/step - loss: 0.0341 - accuracy: 0.9876 - val_loss: 0.2101 - val_accuracy: 0.9428\nEpoch 33/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.0106 - accuracy: 0.9967\nEpoch 33: val_accuracy did not improve from 0.95662\n1018/1018 [==============================] - 37s 37ms/step - loss: 0.0106 - accuracy: 0.9967 - val_loss: 0.2418 - val_accuracy: 0.9329\nEpoch 34/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.0070 - accuracy: 0.9977\nEpoch 34: val_accuracy did not improve from 0.95662\n1018/1018 [==============================] - 38s 37ms/step - loss: 0.0070 - accuracy: 0.9977 - val_loss: 0.1702 - val_accuracy: 0.9538\nEpoch 35/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.0049 - accuracy: 0.9986\nEpoch 35: val_accuracy did not improve from 0.95662\n1018/1018 [==============================] - 38s 37ms/step - loss: 0.0049 - accuracy: 0.9986 - val_loss: 0.1814 - val_accuracy: 0.9519\nEpoch 36/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.0031 - accuracy: 0.9994\nEpoch 36: val_accuracy improved from 0.95662 to 0.95763, saving model to PlantVillage38-2Path5-LAB-m4-1.0-best_result.hdf5\n1018/1018 [==============================] - 38s 37ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.1567 - val_accuracy: 0.9576\nEpoch 37/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.0019 - accuracy: 0.9995\nEpoch 37: val_accuracy improved from 0.95763 to 0.95865, saving model to PlantVillage38-2Path5-LAB-m4-1.0-best_result.hdf5\n1018/1018 [==============================] - 38s 37ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.1593 - val_accuracy: 0.9586\nEpoch 38/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.0022 - accuracy: 0.9994\nEpoch 38: val_accuracy did not improve from 0.95865\n1018/1018 [==============================] - 37s 37ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.1694 - val_accuracy: 0.9569\nEpoch 39/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.0028 - accuracy: 0.9996\nEpoch 39: val_accuracy did not improve from 0.95865\n1018/1018 [==============================] - 37s 37ms/step - loss: 0.0028 - accuracy: 0.9996 - val_loss: 0.1766 - val_accuracy: 0.9552\nEpoch 40/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.0020 - accuracy: 0.9997\nEpoch 40: val_accuracy did not improve from 0.95865\n1018/1018 [==============================] - 38s 37ms/step - loss: 0.0020 - accuracy: 0.9997 - val_loss: 0.1769 - val_accuracy: 0.9538\nEpoch 41/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.0012 - accuracy: 0.9997\nEpoch 41: val_accuracy improved from 0.95865 to 0.96003, saving model to PlantVillage38-2Path5-LAB-m4-1.0-best_result.hdf5\n1018/1018 [==============================] - 38s 37ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.1523 - val_accuracy: 0.9600\nEpoch 42/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.0018 - accuracy: 0.9997\nEpoch 42: val_accuracy did not improve from 0.96003\n1018/1018 [==============================] - 38s 37ms/step - loss: 0.0018 - accuracy: 0.9997 - val_loss: 0.1642 - val_accuracy: 0.9574\nEpoch 43/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.0013 - accuracy: 0.9998\nEpoch 43: val_accuracy improved from 0.96003 to 0.96095, saving model to PlantVillage38-2Path5-LAB-m4-1.0-best_result.hdf5\n1018/1018 [==============================] - 38s 37ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.1503 - val_accuracy: 0.9610\nEpoch 44/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.0012 - accuracy: 0.9998\nEpoch 44: val_accuracy did not improve from 0.96095\n1018/1018 [==============================] - 37s 37ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.1506 - val_accuracy: 0.9606\nEpoch 45/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.0016 - accuracy: 0.9996\nEpoch 45: val_accuracy did not improve from 0.96095\n1018/1018 [==============================] - 37s 37ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.1609 - val_accuracy: 0.9581\nEpoch 46/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 0.9998\nEpoch 46: val_accuracy did not improve from 0.96095\n1018/1018 [==============================] - 37s 37ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.1601 - val_accuracy: 0.9595\nEpoch 47/90\n1017/1018 [============================>.] - ETA: 0s - loss: 5.5703e-04 - accuracy: 0.9999\nEpoch 47: val_accuracy did not improve from 0.96095\n1018/1018 [==============================] - 37s 37ms/step - loss: 5.5702e-04 - accuracy: 0.9999 - val_loss: 0.1546 - val_accuracy: 0.9608\nEpoch 48/90\n1017/1018 [============================>.] - ETA: 0s - loss: 6.4584e-04 - accuracy: 1.0000\nEpoch 48: val_accuracy did not improve from 0.96095\n1018/1018 [==============================] - 37s 37ms/step - loss: 6.4706e-04 - accuracy: 1.0000 - val_loss: 0.1537 - val_accuracy: 0.9602\nEpoch 49/90\n1017/1018 [============================>.] - ETA: 0s - loss: 4.9835e-04 - accuracy: 1.0000\nEpoch 49: val_accuracy did not improve from 0.96095\n1018/1018 [==============================] - 37s 37ms/step - loss: 4.9807e-04 - accuracy: 1.0000 - val_loss: 0.1529 - val_accuracy: 0.9609\nEpoch 50/90\n1017/1018 [============================>.] - ETA: 0s - loss: 4.9585e-04 - accuracy: 1.0000\nEpoch 50: val_accuracy improved from 0.96095 to 0.96233, saving model to PlantVillage38-2Path5-LAB-m4-1.0-best_result.hdf5\n1018/1018 [==============================] - 38s 37ms/step - loss: 4.9558e-04 - accuracy: 1.0000 - val_loss: 0.1503 - val_accuracy: 0.9623\nEpoch 51/90\n1017/1018 [============================>.] - ETA: 0s - loss: 5.5234e-04 - accuracy: 0.9999\nEpoch 51: val_accuracy did not improve from 0.96233\n1018/1018 [==============================] - 37s 36ms/step - loss: 5.5199e-04 - accuracy: 0.9999 - val_loss: 0.1515 - val_accuracy: 0.9617\nEpoch 52/90\n1017/1018 [============================>.] - ETA: 0s - loss: 4.9170e-04 - accuracy: 1.0000\nEpoch 52: val_accuracy did not improve from 0.96233\n1018/1018 [==============================] - 37s 36ms/step - loss: 4.9183e-04 - accuracy: 1.0000 - val_loss: 0.1551 - val_accuracy: 0.9621\nEpoch 53/90\n1017/1018 [============================>.] - ETA: 0s - loss: 6.8096e-04 - accuracy: 0.9999\nEpoch 53: val_accuracy did not improve from 0.96233\n1018/1018 [==============================] - 37s 36ms/step - loss: 6.8092e-04 - accuracy: 0.9999 - val_loss: 0.1624 - val_accuracy: 0.9613\nEpoch 54/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.0048 - accuracy: 0.9991\nEpoch 54: val_accuracy did not improve from 0.96233\n1018/1018 [==============================] - 37s 36ms/step - loss: 0.0048 - accuracy: 0.9991 - val_loss: 0.1859 - val_accuracy: 0.9551\nEpoch 55/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.0040 - accuracy: 0.9990\nEpoch 55: val_accuracy did not improve from 0.96233\n1018/1018 [==============================] - 37s 36ms/step - loss: 0.0040 - accuracy: 0.9990 - val_loss: 0.1916 - val_accuracy: 0.9525\nEpoch 56/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.0020 - accuracy: 0.9995\nEpoch 56: val_accuracy did not improve from 0.96233\n1018/1018 [==============================] - 37s 36ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.1989 - val_accuracy: 0.9535\nEpoch 57/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.0017 - accuracy: 0.9996\nEpoch 57: val_accuracy did not improve from 0.96233\n1018/1018 [==============================] - 37s 36ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.1757 - val_accuracy: 0.9577\nEpoch 58/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.0012 - accuracy: 0.9998\nEpoch 58: val_accuracy did not improve from 0.96233\n1018/1018 [==============================] - 37s 36ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.1641 - val_accuracy: 0.9597\nEpoch 59/90\n1017/1018 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 0.9998\nEpoch 59: val_accuracy did not improve from 0.96233\n1018/1018 [==============================] - 37s 36ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.1572 - val_accuracy: 0.9621\nEpoch 60/90\n1017/1018 [============================>.] - ETA: 0s - loss: 7.6278e-04 - accuracy: 0.9999\nEpoch 60: val_accuracy did not improve from 0.96233\n1018/1018 [==============================] - 37s 36ms/step - loss: 7.6234e-04 - accuracy: 0.9999 - val_loss: 0.1668 - val_accuracy: 0.9586\nEpoch 61/90\n1017/1018 [============================>.] - ETA: 0s - loss: 8.8488e-04 - accuracy: 0.9998\nEpoch 61: val_accuracy did not improve from 0.96233\n1018/1018 [==============================] - 37s 36ms/step - loss: 8.8435e-04 - accuracy: 0.9998 - val_loss: 0.2157 - val_accuracy: 0.9496\nEpoch 62/90\n1017/1018 [============================>.] - ETA: 0s - loss: 5.8235e-04 - accuracy: 0.9999\nEpoch 62: val_accuracy did not improve from 0.96233\n1018/1018 [==============================] - 37s 36ms/step - loss: 5.8265e-04 - accuracy: 0.9999 - val_loss: 0.1579 - val_accuracy: 0.9620\nEpoch 63/90\n1017/1018 [============================>.] - ETA: 0s - loss: 4.5320e-04 - accuracy: 0.9999\nEpoch 63: val_accuracy did not improve from 0.96233\n1018/1018 [==============================] - 37s 36ms/step - loss: 4.5749e-04 - accuracy: 0.9999 - val_loss: 0.1576 - val_accuracy: 0.9617\nEpoch 64/90\n1017/1018 [============================>.] - ETA: 0s - loss: 6.4694e-04 - accuracy: 0.9999\nEpoch 64: val_accuracy did not improve from 0.96233\n1018/1018 [==============================] - 37s 36ms/step - loss: 6.4656e-04 - accuracy: 0.9999 - val_loss: 0.1634 - val_accuracy: 0.9605\nEpoch 65/90\n1017/1018 [============================>.] - ETA: 0s - loss: 5.7138e-04 - accuracy: 0.9999\nEpoch 65: val_accuracy did not improve from 0.96233\n1018/1018 [==============================] - 37s 36ms/step - loss: 5.7217e-04 - accuracy: 0.9999 - val_loss: 0.1664 - val_accuracy: 0.9598\nEpoch 66/90\n1017/1018 [============================>.] - ETA: 0s - loss: 4.3847e-04 - accuracy: 1.0000\nEpoch 66: val_accuracy did not improve from 0.96233\n1018/1018 [==============================] - 37s 36ms/step - loss: 4.3821e-04 - accuracy: 1.0000 - val_loss: 0.1548 - val_accuracy: 0.9621\nEpoch 67/90\n1017/1018 [============================>.] - ETA: 0s - loss: 5.7464e-04 - accuracy: 0.9999\nEpoch 67: val_accuracy did not improve from 0.96233\n1018/1018 [==============================] - 37s 36ms/step - loss: 5.7430e-04 - accuracy: 0.9999 - val_loss: 0.1628 - val_accuracy: 0.9598\nEpoch 68/90\n1017/1018 [============================>.] - ETA: 0s - loss: 6.2589e-04 - accuracy: 0.9998\nEpoch 68: val_accuracy did not improve from 0.96233\n1018/1018 [==============================] - 37s 36ms/step - loss: 6.2547e-04 - accuracy: 0.9998 - val_loss: 0.1597 - val_accuracy: 0.9608\nEpoch 69/90\n1017/1018 [============================>.] - ETA: 0s - loss: 6.0573e-04 - accuracy: 0.9998\nEpoch 69: val_accuracy did not improve from 0.96233\n1018/1018 [==============================] - 37s 36ms/step - loss: 6.0841e-04 - accuracy: 0.9998 - val_loss: 0.1641 - val_accuracy: 0.9601\nEpoch 70/90\n1017/1018 [============================>.] - ETA: 0s - loss: 5.9158e-04 - accuracy: 0.9999\nEpoch 70: val_accuracy did not improve from 0.96233\n1018/1018 [==============================] - 37s 36ms/step - loss: 5.9125e-04 - accuracy: 0.9999 - val_loss: 0.1823 - val_accuracy: 0.9571\nEpoch 71/90\n1017/1018 [============================>.] - ETA: 0s - loss: 3.5617e-04 - accuracy: 0.9999\nEpoch 71: val_accuracy did not improve from 0.96233\n1018/1018 [==============================] - 37s 36ms/step - loss: 3.5594e-04 - accuracy: 0.9999 - val_loss: 0.1582 - val_accuracy: 0.9620\nEpoch 72/90\n1017/1018 [============================>.] - ETA: 0s - loss: 3.9575e-04 - accuracy: 1.0000\nEpoch 72: val_accuracy did not improve from 0.96233\n1018/1018 [==============================] - 37s 37ms/step - loss: 3.9551e-04 - accuracy: 1.0000 - val_loss: 0.1600 - val_accuracy: 0.9609\nEpoch 73/90\n1017/1018 [============================>.] - ETA: 0s - loss: 3.0103e-04 - accuracy: 1.0000\nEpoch 73: val_accuracy improved from 0.96233 to 0.96261, saving model to PlantVillage38-2Path5-LAB-m4-1.0-best_result.hdf5\n1018/1018 [==============================] - 38s 37ms/step - loss: 3.0086e-04 - accuracy: 1.0000 - val_loss: 0.1586 - val_accuracy: 0.9626\nEpoch 74/90\n1017/1018 [============================>.] - ETA: 0s - loss: 4.3711e-04 - accuracy: 0.9999\nEpoch 74: val_accuracy did not improve from 0.96261\n1018/1018 [==============================] - 37s 36ms/step - loss: 4.3696e-04 - accuracy: 0.9999 - val_loss: 0.1613 - val_accuracy: 0.9617\nEpoch 75/90\n1017/1018 [============================>.] - ETA: 0s - loss: 3.7938e-04 - accuracy: 1.0000\nEpoch 75: val_accuracy did not improve from 0.96261\n1018/1018 [==============================] - 37s 36ms/step - loss: 3.7916e-04 - accuracy: 1.0000 - val_loss: 0.1609 - val_accuracy: 0.9615\nEpoch 76/90\n1017/1018 [============================>.] - ETA: 0s - loss: 3.7860e-04 - accuracy: 0.9998\nEpoch 76: val_accuracy did not improve from 0.96261\n1018/1018 [==============================] - 37s 36ms/step - loss: 3.7886e-04 - accuracy: 0.9998 - val_loss: 0.1709 - val_accuracy: 0.9600\nEpoch 77/90\n1017/1018 [============================>.] - ETA: 0s - loss: 3.6631e-04 - accuracy: 0.9999\nEpoch 77: val_accuracy did not improve from 0.96261\n1018/1018 [==============================] - 37s 36ms/step - loss: 3.6671e-04 - accuracy: 0.9999 - val_loss: 0.1597 - val_accuracy: 0.9621\nEpoch 78/90\n1017/1018 [============================>.] - ETA: 0s - loss: 3.2694e-04 - accuracy: 1.0000\nEpoch 78: val_accuracy did not improve from 0.96261\n1018/1018 [==============================] - 37s 36ms/step - loss: 3.2680e-04 - accuracy: 1.0000 - val_loss: 0.1585 - val_accuracy: 0.9613\nEpoch 79/90\n1017/1018 [============================>.] - ETA: 0s - loss: 2.9517e-04 - accuracy: 0.9999\nEpoch 79: val_accuracy improved from 0.96261 to 0.96270, saving model to PlantVillage38-2Path5-LAB-m4-1.0-best_result.hdf5\n1018/1018 [==============================] - 37s 36ms/step - loss: 2.9494e-04 - accuracy: 0.9999 - val_loss: 0.1569 - val_accuracy: 0.9627\nEpoch 80/90\n1017/1018 [============================>.] - ETA: 0s - loss: 3.0073e-04 - accuracy: 1.0000\nEpoch 80: val_accuracy did not improve from 0.96270\n1018/1018 [==============================] - 37s 36ms/step - loss: 3.0051e-04 - accuracy: 1.0000 - val_loss: 0.1587 - val_accuracy: 0.9618\nEpoch 81/90\n1017/1018 [============================>.] - ETA: 0s - loss: 3.4643e-04 - accuracy: 0.9999\nEpoch 81: val_accuracy did not improve from 0.96270\n1018/1018 [==============================] - 37s 36ms/step - loss: 3.4629e-04 - accuracy: 0.9999 - val_loss: 0.1646 - val_accuracy: 0.9599\nEpoch 82/90\n1017/1018 [============================>.] - ETA: 0s - loss: 2.7103e-04 - accuracy: 1.0000\nEpoch 82: val_accuracy did not improve from 0.96270\n1018/1018 [==============================] - 37s 36ms/step - loss: 2.7082e-04 - accuracy: 1.0000 - val_loss: 0.1556 - val_accuracy: 0.9626\nEpoch 83/90\n1017/1018 [============================>.] - ETA: 0s - loss: 4.6212e-04 - accuracy: 0.9999\nEpoch 83: val_accuracy did not improve from 0.96270\n1018/1018 [==============================] - 37s 36ms/step - loss: 4.6185e-04 - accuracy: 0.9999 - val_loss: 0.1590 - val_accuracy: 0.9617\nEpoch 84/90\n1017/1018 [============================>.] - ETA: 0s - loss: 3.0219e-04 - accuracy: 1.0000\nEpoch 84: val_accuracy did not improve from 0.96270\n1018/1018 [==============================] - 37s 36ms/step - loss: 3.0396e-04 - accuracy: 1.0000 - val_loss: 0.1588 - val_accuracy: 0.9617\nEpoch 85/90\n1017/1018 [============================>.] - ETA: 0s - loss: 2.9728e-04 - accuracy: 1.0000\nEpoch 85: val_accuracy did not improve from 0.96270\n1018/1018 [==============================] - 37s 36ms/step - loss: 2.9713e-04 - accuracy: 1.0000 - val_loss: 0.1590 - val_accuracy: 0.9619\nEpoch 86/90\n1017/1018 [============================>.] - ETA: 0s - loss: 3.5887e-04 - accuracy: 0.9999\nEpoch 86: val_accuracy did not improve from 0.96270\n1018/1018 [==============================] - 37s 36ms/step - loss: 3.5868e-04 - accuracy: 0.9999 - val_loss: 0.1597 - val_accuracy: 0.9606\nEpoch 87/90\n1017/1018 [============================>.] - ETA: 0s - loss: 2.3834e-04 - accuracy: 1.0000\nEpoch 87: val_accuracy did not improve from 0.96270\n1018/1018 [==============================] - 37s 36ms/step - loss: 2.3834e-04 - accuracy: 1.0000 - val_loss: 0.1546 - val_accuracy: 0.9623\nEpoch 88/90\n1017/1018 [============================>.] - ETA: 0s - loss: 2.6700e-04 - accuracy: 1.0000\nEpoch 88: val_accuracy did not improve from 0.96270\n1018/1018 [==============================] - 37s 36ms/step - loss: 2.6685e-04 - accuracy: 1.0000 - val_loss: 0.1579 - val_accuracy: 0.9621\nEpoch 89/90\n1017/1018 [============================>.] - ETA: 0s - loss: 2.4064e-04 - accuracy: 1.0000\nEpoch 89: val_accuracy did not improve from 0.96270\n1018/1018 [==============================] - 37s 36ms/step - loss: 2.4046e-04 - accuracy: 1.0000 - val_loss: 0.1565 - val_accuracy: 0.9625\nEpoch 90/90\n1017/1018 [============================>.] - ETA: 0s - loss: 1.8509e-04 - accuracy: 1.0000\nEpoch 90: val_accuracy did not improve from 0.96270\n1018/1018 [==============================] - 37s 36ms/step - loss: 1.8499e-04 - accuracy: 1.0000 - val_loss: 0.1556 - val_accuracy: 0.9626\nHistory saved.\nTesting Last Model: PlantVillage38-2Path5-LAB-m4-1.0\n340/340 [==============================] - 4s 13ms/step - loss: 0.1560 - accuracy: 0.9627\nloss 0.15600240230560303\nacc 0.962670087814331\nBest Model Results: PlantVillage38-2Path5-LAB-m4-1.0\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)","Cell \u001b[0;32mIn[8], line 69\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBest Model Results: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mbasefilename)\n\u001b[1;32m     64\u001b[0m model \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mload_model(\n\u001b[1;32m     65\u001b[0m     best_result_file_name,\n\u001b[1;32m     66\u001b[0m     custom_objects\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCopyChannels\u001b[39m\u001b[38;5;124m'\u001b[39m: cai\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mCopyChannels}\n\u001b[1;32m     67\u001b[0m )\n\u001b[0;32m---> 69\u001b[0m evaluated \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtest_y\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# cai.models.save_model(model, basefilename)\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m metric, name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(evaluated,[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124macc\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop 5 acc\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:98\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m     96\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[1;32m     97\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."],"ename":"InternalError","evalue":"Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Calcutale F1 and other metrics","metadata":{}},{"cell_type":"code","source":"for l_ratio in [0.0,0.25,0.5,0.75,1.0]:\n    \n    basefilename = basename + str(l_ratio)\n    \n    best_result_file_name = basefilename+'-best_result.hdf5'\n    \n    print('Best Model Results: '+basefilename)\n    \n    model = tf.keras.models.load_model(\n        best_result_file_name,\n        custom_objects={'CopyChannels': cai.layers.CopyChannels}\n    )\n    \n    pred_y = model.predict(test_x)\n    #         print(\"Predicted Shape:\", pred_y.shape)\n    pred_classes_y = np.array(list(np.argmax(pred_y, axis=1)))\n    test_classes_y = np.array(list(np.argmax(test_y, axis=1)))\n    #         print(\"Pred classes shape:\",pred_classes_y.shape)\n    #         print(\"Test classes shape:\",test_classes_y.shape)\n    report = classification_report(test_classes_y, pred_classes_y, digits=4)\n    print(report)","metadata":{"execution":{"iopub.status.busy":"2024-01-23T19:08:30.155713Z","iopub.execute_input":"2024-01-23T19:08:30.156183Z","iopub.status.idle":"2024-01-23T19:16:38.190045Z","shell.execute_reply.started":"2024-01-23T19:08:30.156145Z","shell.execute_reply":"2024-01-23T19:16:38.188774Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Best Model Results: PlantVillage38-2Path5-LAB-m4-0.0\n340/340 [==============================] - 85s 247ms/step\n              precision    recall  f1-score   support\n\n           0     0.9921    1.0000    0.9960       126\n           1     1.0000    1.0000    1.0000       125\n           2     1.0000    1.0000    1.0000        55\n           3     0.9848    0.9848    0.9848       329\n           4     0.9836    0.9967    0.9901       301\n           5     0.9953    1.0000    0.9976       211\n           6     0.9942    1.0000    0.9971       171\n           7     0.8962    0.9223    0.9091       103\n           8     0.9958    1.0000    0.9979       239\n           9     0.9684    0.9340    0.9509       197\n          10     0.9957    1.0000    0.9979       233\n          11     0.9958    1.0000    0.9979       236\n          12     1.0000    0.9964    0.9982       277\n          13     0.9954    1.0000    0.9977       216\n          14     0.9884    1.0000    0.9942        85\n          15     0.9973    0.9991    0.9982      1102\n          16     0.9957    0.9978    0.9967       460\n          17     0.9863    1.0000    0.9931        72\n          18     0.9804    1.0000    0.9901       200\n          19     0.9966    0.9899    0.9932       296\n          20     0.9900    0.9950    0.9925       200\n          21     0.9848    0.9750    0.9799       200\n          22     1.0000    0.9355    0.9667        31\n          23     1.0000    0.9867    0.9933        75\n          24     1.0000    0.9990    0.9995      1018\n          25     1.0000    1.0000    1.0000       367\n          26     0.9955    0.9955    0.9955       222\n          27     1.0000    1.0000    1.0000        92\n          28     0.9953    0.9953    0.9953       426\n          29     0.9698    0.9650    0.9674       200\n          30     0.9813    0.9634    0.9723       382\n          31     0.9948    0.9948    0.9948       191\n          32     0.9972    0.9915    0.9944       355\n          33     0.9853    0.9970    0.9911       336\n          34     0.9858    0.9858    0.9858       281\n          35     0.9991    0.9963    0.9977      1072\n          36     0.9868    1.0000    0.9934        75\n          37     0.9937    0.9937    0.9937       319\n\n    accuracy                         0.9925     10876\n   macro avg     0.9895    0.9892    0.9893     10876\nweighted avg     0.9925    0.9925    0.9924     10876\n\nBest Model Results: PlantVillage38-2Path5-LAB-m4-0.25\n340/340 [==============================] - 77s 224ms/step\n              precision    recall  f1-score   support\n\n           0     1.0000    0.9921    0.9960       126\n           1     1.0000    0.9920    0.9960       125\n           2     1.0000    1.0000    1.0000        55\n           3     0.9969    0.9909    0.9939       329\n           4     1.0000    1.0000    1.0000       301\n           5     1.0000    1.0000    1.0000       211\n           6     1.0000    1.0000    1.0000       171\n           7     0.9048    0.9223    0.9135       103\n           8     1.0000    1.0000    1.0000       239\n           9     0.9588    0.9442    0.9514       197\n          10     0.9957    1.0000    0.9979       233\n          11     1.0000    1.0000    1.0000       236\n          12     1.0000    1.0000    1.0000       277\n          13     1.0000    1.0000    1.0000       216\n          14     0.9884    1.0000    0.9942        85\n          15     1.0000    1.0000    1.0000      1102\n          16     0.9935    1.0000    0.9967       460\n          17     0.9863    1.0000    0.9931        72\n          18     0.9804    1.0000    0.9901       200\n          19     0.9933    0.9966    0.9949       296\n          20     1.0000    1.0000    1.0000       200\n          21     0.9899    0.9850    0.9875       200\n          22     1.0000    1.0000    1.0000        31\n          23     1.0000    1.0000    1.0000        75\n          24     0.9980    0.9990    0.9985      1018\n          25     0.9973    1.0000    0.9986       367\n          26     1.0000    0.9955    0.9977       222\n          27     1.0000    1.0000    1.0000        92\n          28     0.9907    0.9953    0.9930       426\n          29     0.9701    0.9750    0.9726       200\n          30     0.9894    0.9817    0.9855       382\n          31     0.9948    1.0000    0.9974       191\n          32     0.9972    0.9915    0.9944       355\n          33     0.9882    0.9970    0.9926       336\n          34     0.9964    0.9858    0.9911       281\n          35     0.9991    0.9935    0.9963      1072\n          36     0.9868    1.0000    0.9934        75\n          37     1.0000    1.0000    1.0000       319\n\n    accuracy                         0.9946     10876\n   macro avg     0.9920    0.9931    0.9925     10876\nweighted avg     0.9946    0.9946    0.9946     10876\n\nBest Model Results: PlantVillage38-2Path5-LAB-m4-0.5\n340/340 [==============================] - 71s 207ms/step\n              precision    recall  f1-score   support\n\n           0     1.0000    0.9841    0.9920       126\n           1     0.9921    1.0000    0.9960       125\n           2     1.0000    1.0000    1.0000        55\n           3     1.0000    0.9939    0.9970       329\n           4     1.0000    1.0000    1.0000       301\n           5     0.9953    1.0000    0.9976       211\n           6     1.0000    1.0000    1.0000       171\n           7     0.8981    0.9417    0.9194       103\n           8     1.0000    1.0000    1.0000       239\n           9     0.9635    0.9391    0.9512       197\n          10     0.9915    1.0000    0.9957       233\n          11     1.0000    1.0000    1.0000       236\n          12     1.0000    1.0000    1.0000       277\n          13     1.0000    1.0000    1.0000       216\n          14     1.0000    1.0000    1.0000        85\n          15     1.0000    1.0000    1.0000      1102\n          16     0.9957    0.9978    0.9967       460\n          17     1.0000    1.0000    1.0000        72\n          18     0.9900    0.9950    0.9925       200\n          19     0.9966    0.9932    0.9949       296\n          20     0.9804    1.0000    0.9901       200\n          21     0.9802    0.9900    0.9851       200\n          22     0.9118    1.0000    0.9538        31\n          23     1.0000    1.0000    1.0000        75\n          24     0.9980    0.9971    0.9975      1018\n          25     1.0000    1.0000    1.0000       367\n          26     1.0000    1.0000    1.0000       222\n          27     1.0000    1.0000    1.0000        92\n          28     0.9953    1.0000    0.9977       426\n          29     0.9704    0.9850    0.9777       200\n          30     0.9920    0.9712    0.9815       382\n          31     0.9745    1.0000    0.9871       191\n          32     0.9972    0.9915    0.9944       355\n          33     0.9970    1.0000    0.9985       336\n          34     1.0000    0.9893    0.9946       281\n          35     1.0000    0.9944    0.9972      1072\n          36     1.0000    1.0000    1.0000        75\n          37     1.0000    0.9969    0.9984       319\n\n    accuracy                         0.9947     10876\n   macro avg     0.9900    0.9937    0.9918     10876\nweighted avg     0.9948    0.9947    0.9947     10876\n\nBest Model Results: PlantVillage38-2Path5-LAB-m4-0.75\n340/340 [==============================] - 76s 220ms/step\n              precision    recall  f1-score   support\n\n           0     1.0000    0.9841    0.9920       126\n           1     0.9843    1.0000    0.9921       125\n           2     1.0000    1.0000    1.0000        55\n           3     0.9939    0.9939    0.9939       329\n           4     0.9967    1.0000    0.9983       301\n           5     0.9953    1.0000    0.9976       211\n           6     1.0000    1.0000    1.0000       171\n           7     0.8952    0.9126    0.9038       103\n           8     1.0000    1.0000    1.0000       239\n           9     0.9538    0.9442    0.9490       197\n          10     0.9957    1.0000    0.9979       233\n          11     1.0000    0.9958    0.9979       236\n          12     0.9964    1.0000    0.9982       277\n          13     0.9954    0.9954    0.9954       216\n          14     0.9884    1.0000    0.9942        85\n          15     1.0000    1.0000    1.0000      1102\n          16     1.0000    0.9978    0.9989       460\n          17     0.9863    1.0000    0.9931        72\n          18     0.9950    0.9950    0.9950       200\n          19     0.9966    1.0000    0.9983       296\n          20     0.9901    1.0000    0.9950       200\n          21     0.9754    0.9900    0.9826       200\n          22     1.0000    0.9677    0.9836        31\n          23     1.0000    1.0000    1.0000        75\n          24     0.9990    0.9971    0.9980      1018\n          25     1.0000    1.0000    1.0000       367\n          26     0.9955    1.0000    0.9978       222\n          27     1.0000    1.0000    1.0000        92\n          28     0.9953    0.9906    0.9929       426\n          29     0.9801    0.9850    0.9825       200\n          30     0.9946    0.9660    0.9801       382\n          31     0.9795    1.0000    0.9896       191\n          32     0.9972    0.9972    0.9972       355\n          33     0.9941    0.9970    0.9955       336\n          34     0.9929    0.9893    0.9911       281\n          35     0.9981    0.9953    0.9967      1072\n          36     1.0000    1.0000    1.0000        75\n          37     0.9907    1.0000    0.9953       319\n\n    accuracy                         0.9941     10876\n   macro avg     0.9909    0.9919    0.9914     10876\nweighted avg     0.9941    0.9941    0.9941     10876\n\nBest Model Results: PlantVillage38-2Path5-LAB-m4-1.0\n340/340 [==============================] - 84s 245ms/step\n              precision    recall  f1-score   support\n\n           0     0.9444    0.9444    0.9444       126\n           1     0.9603    0.9680    0.9641       125\n           2     0.9636    0.9636    0.9636        55\n           3     0.9699    0.9787    0.9743       329\n           4     0.9771    0.9934    0.9852       301\n           5     0.9856    0.9763    0.9810       211\n           6     0.9942    0.9942    0.9942       171\n           7     0.8878    0.8447    0.8657       103\n           8     0.9876    0.9958    0.9917       239\n           9     0.9204    0.9391    0.9296       197\n          10     0.9957    1.0000    0.9979       233\n          11     0.9602    0.9195    0.9394       236\n          12     0.9338    0.9675    0.9504       277\n          13     0.9908    1.0000    0.9954       216\n          14     1.0000    1.0000    1.0000        85\n          15     0.9955    0.9955    0.9955      1102\n          16     0.9619    0.9870    0.9742       460\n          17     0.9583    0.9583    0.9583        72\n          18     0.9381    0.9850    0.9610       200\n          19     0.9860    0.9493    0.9673       296\n          20     0.9552    0.9600    0.9576       200\n          21     0.9024    0.9250    0.9136       200\n          22     0.8571    0.7742    0.8136        31\n          23     1.0000    0.9867    0.9933        75\n          24     0.9912    0.9971    0.9941      1018\n          25     0.9812    0.9973    0.9892       367\n          26     0.9910    0.9955    0.9933       222\n          27     0.9890    0.9783    0.9836        92\n          28     0.9715    0.9601    0.9658       426\n          29     0.8802    0.7350    0.8011       200\n          30     0.9133    0.8822    0.8975       382\n          31     0.9267    0.9267    0.9267       191\n          32     0.9035    0.8704    0.8867       355\n          33     0.9186    0.9405    0.9294       336\n          34     0.9225    0.8897    0.9058       281\n          35     0.9770    0.9925    0.9847      1072\n          36     0.8608    0.9067    0.8831        75\n          37     0.9665    0.9937    0.9799       319\n\n    accuracy                         0.9634     10876\n   macro avg     0.9531    0.9493    0.9508     10876\nweighted avg     0.9630    0.9634    0.9630     10876\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# Calculate top-5 accuracy\nfor l_ratio in [0.0,0.25,0.5,0.75,1.0]:\n    \n    basefilename = basename + str(l_ratio)\n    \n    best_result_file_name = basefilename+'-best_result.hdf5'    \n   \n    model = tf.keras.models.load_model(\n        best_result_file_name,\n        custom_objects={'CopyChannels': cai.layers.CopyChannels}\n    )\n    \n    pred_y = model.predict(test_x)  \n    \n    top_5_acc = top_k_accuracy(test_y, pred_y, k=5)\n    print(f'{basefilename} Top-5 Accuracy: {top_5_acc}')","metadata":{"execution":{"iopub.status.busy":"2024-01-23T19:17:56.505259Z","iopub.execute_input":"2024-01-23T19:17:56.505739Z","iopub.status.idle":"2024-01-23T19:26:09.367702Z","shell.execute_reply.started":"2024-01-23T19:17:56.505697Z","shell.execute_reply":"2024-01-23T19:26:09.366441Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"340/340 [==============================] - 86s 250ms/step\nPlantVillage38-2Path5-LAB-m4-0.0 Top-5 Accuracy: 0.9999080544317764\n340/340 [==============================] - 76s 222ms/step\nPlantVillage38-2Path5-LAB-m4-0.25 Top-5 Accuracy: 0.999540272158882\n340/340 [==============================] - 71s 207ms/step\nPlantVillage38-2Path5-LAB-m4-0.5 Top-5 Accuracy: 0.9996322177271055\n340/340 [==============================] - 75s 220ms/step\nPlantVillage38-2Path5-LAB-m4-0.75 Top-5 Accuracy: 0.9996322177271055\n340/340 [==============================] - 83s 242ms/step\nPlantVillage38-2Path5-LAB-m4-1.0 Top-5 Accuracy: 0.9973335785215153\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Confusion Matrix","metadata":{}},{"cell_type":"code","source":"for l_ratio in [0.0,0.25,0.50,0.75,1.0]:\n    \n    basefilename = basename + str(l_ratio)\n     \n    best_result_file_name = basefilename+'-best_result.hdf5'          \n\n    print('Best Model Results: '+basefilename)          \n    model = tf.keras.models.load_model(\n        best_result_file_name,\n        custom_objects={'CopyChannels': cai.layers.CopyChannels}\n    )\n\n    # Make predictions\n    y_pred_prob = model.predict(test_x)\n    y_pred = np.argmax(y_pred_prob, axis=1)\n\n    # Create the confusion matrix\n    cm = confusion_matrix(np.argmax(test_y, axis=1), y_pred)\n\n    # Visualize the confusion matrix using seaborn\n    plt.figure(figsize=(8, 6))\n    sns.heatmap(cm, annot=False, fmt='d', cmap='Blues', cbar=False,\n                xticklabels='', yticklabels='')\n    plt.title('Confusion Matrix')\n    plt.xlabel('Predicted')\n    plt.ylabel('True')\n\n    figfilename = basefilename+'-CF.png'\n    plt.savefig(figfilename, bbox_inches='tight')\n\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-01-23T19:31:44.888818Z","iopub.execute_input":"2024-01-23T19:31:44.889643Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Best Model Results: PlantVillage38-2Path5-LAB-m4-0.0\n340/340 [==============================] - 83s 243ms/step\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 800x600 with 1 Axes>","image/png":"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"},"metadata":{}},{"name":"stdout","text":"Best Model Results: PlantVillage38-2Path5-LAB-m4-0.25\n340/340 [==============================] - 76s 222ms/step\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 800x600 with 1 Axes>","image/png":"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"},"metadata":{}},{"name":"stdout","text":"Best Model Results: PlantVillage38-2Path5-LAB-m4-0.5\n340/340 [==============================] - 71s 208ms/step\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 800x600 with 1 Axes>","image/png":"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"},"metadata":{}},{"name":"stdout","text":"Best Model Results: PlantVillage38-2Path5-LAB-m4-0.75\n340/340 [==============================] - 76s 222ms/step\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 800x600 with 1 Axes>","image/png":"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"},"metadata":{}},{"name":"stdout","text":"Best Model Results: PlantVillage38-2Path5-LAB-m4-1.0\n219/340 [==================>...........] - ETA: 29s","output_type":"stream"}]},{"cell_type":"code","source":"!ls","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}